---
- hosts: all
  vars:
    usernames:
       - vagrant
       - hadoop
  remote_user: vagrant
  become: true
  tasks:
  - name: install latest JDK release 
    package:
      name: java-1.8.0-openjdk-devel.x86_64
      state: latest
  - name: add linux user hadoop
    user:
      name: hadoop
      comment: "hadoop service user"
      generate_ssh_key: yes
      ssh_key_file: .ssh/id_rsa
      ssh_key_comment: "passwordless ssh"
      ssh_key_passphrase:
      ssh_key_type: rsa
#  - name: set authorized key from file
#    authorized_key:
#      user: hadoop
#      state: present
#      key: "{{ lookup('file', '/home/hadoop/.ssh/id_rsa.pub') }}"
  - name: edit ssh config to allow hadoop user
    lineinfile:
      dest: /etc/ssh/sshd_config
      regexp: '^AllowUsers'
      line: "AllowUsers {{usernames | join(' ')}}"
      create: yes
  - name: edit ssh config to allow PubKeyAuthentication
    lineinfile:
      dest: /etc/ssh/sshd_config
      regexp: '^#PubkeyAuthentication.*'
      line: 'PubkeyAuthentication yes'
      create: yes
  - name: get JAVA_HOME
    shell: "dirname $(dirname $(readlink -f $(which javac)))"
    register: JAVA_HOME
  - name: export JAVA_HOME for users
    lineinfile:
      path: /home/vagrant/.bashrc
      line: export JAVA_HOME={{ JAVA_HOME.stdout }}
      state: present
      create: yes
  - name: export JAVA_HOME for users
    lineinfile:
      path: /home/hadoop/.bashrc
      line: export JAVA_HOME={{ JAVA_HOME.stdout }}
      state: present
      create: yes
  - name: export HADOOP_HOME for vagrant user
    lineinfile:
      path: /home/vagrant/.bashrc
      line: export HADOOP_HOME=/opt/hadoop/hadoop-2.7.1
      state: present
      create: yes
  - name: export HADOOP_HOME for hadoop user
    lineinfile:
      path: /home/hadoop/.bashrc
      line: export HADOOP_HOME=/opt/hadoop/hadoop-2.7.1
      state: present
      create: yes
  - name: alias hdfs for hadoop user
    lineinfile:
      path: /home/hadoop/.bashrc
      line: alias hdfs=$HADOOP_HOME/bin/hdfs
      state: present
      create: yes
  - name: alias hdfs for vagrant user
    lineinfile:
      path: /home/vagrant/.bashrc
      line: alias hdfs=$HADOOP_HOME/bin/hdfs
      state: present
      create: yes
  - name: download hadoop release
    get_url:
      url: http://mirrors.advancedhosters.com/apache/hadoop/common/hadoop-2.7.1/hadoop-2.7.1.tar.gz
      dest: /tmp/hadoop-2.7.1.tar.gz
      checksum: "sha1:8AA2E1E8DBE0EFEB2E98AC24C0EAE37C5F94764C"
#      url: http://mirrors.advancedhosters.com/apache/hadoop/common/hadoop-3.0.0-alpha4/hadoop-3.0.0-alpha4.tar.gz
#      dest: /tmp/hadoop-3.0.0-alpha4.tar.gz

  - name: create hadoop directory
    file:
      path: /opt/hadoop
      state: directory
      owner: hadoop
      group: hadoop
      mode: 0775
  - name: extract hadoop release
    unarchive:
##      src: http://mirrors.advancedhosters.com/apache/hadoop/common/hadoop-3.0.0-alpha4/hadoop-3.0.0-alpha4.tar.gz
      src: /tmp/hadoop-2.7.1.tar.gz
      dest: /opt/hadoop
      remote_src: yes
      keep_newer: yes
      creates: /opt/hadoop/hadoop-2.7.1
  - name: configure core-site.xml
    template:
      src: templates/hadoop/core-site.xml
      dest: /opt/hadoop/hadoop-2.7.1/etc/hadoop/core-site.xml
  - name: configure hdfs-site.xml
    template:
      src: templates/hadoop/hdfs-site.xml
      dest: /opt/hadoop/hadoop-2.7.1/etc/hadoop/hdfs-site.xml
  - name: configure mapred-site.xml
    template:
      src: templates/hadoop/mapred-site.xml
      dest: /opt/hadoop/hadoop-2.7.1/etc/hadoop/mapred-site.xml
  - name: configure yarn-site.xml
    template:
      src: templates/hadoop/yarn-site.xml
      dest: /opt/hadoop/hadoop-2.7.1/etc/hadoop/yarn-site.xml
  - name: change hadoop directory permissions
    file:
      path: /opt/hadoop/hadoop-2.7.1
      state: directory
      owner: hadoop
      group: hadoop
      mode: 0775
      recurse: yes
  - name: restart sshd service
    service:
      name: sshd
      state: restarted
